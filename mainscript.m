% mainscript is rather short this time% primary component countcomp_count = 40; [tvec tlab tstv tstl] = readSets();  % Calls a function `readSets()` that returns:  % - `tvec`: Training vectors (each row = one image, flattened)  % - `tlab`: Training labels (each label = one digit 0–9)  % - `tstv`: Test vectors (same structure as tvec)  % - `tstl`: Test labels  % shift labels by one to use labels directly as indices , MATLAB indices start at 1, but MNIST labels start at 0.tlab += 1;tstl += 1;% look at the 100 digits in the training set% `imsize = 28` defines the height/width of each image (MNIST standard size).% `fim` is a large empty matrix that will hold a **grid of 10×10 images**, each separated by 2 pixels of padding.imsize = 28;     fim = zeros((imsize + 2) * 10 + 2);% We loop through digits 1 to 10. For each digit, we find the first 10 training samples that belong to that class. % Then we’ll place them in one row of our image grid.for clid = 1:10  rowid = (clid - 1) * (imsize + 2) + 3;  clsamples = find(tlab == clid)(1:10); % - `spid`: The position (1–10) of the sample in that row.% - `colid`: The starting column in `fim` where this image will go.% - `reshape(...)`: Converts the flattened image vector back into a **28×28** 2D image.% - The final assignment places that 28×28 image into the right location on the `fim` grid.  for spid = 1:10	colid = (spid - 1) * (imsize + 2) + 3;	im = 1-reshape(tvec(clsamples(spid),:), imsize, imsize)';	fim(rowid:rowid+imsize-1, colid:colid+imsize-1) = im;  endendimshow(fim)% check number of samples in each class% - The line `[labels; sum(tlab == labels); sum(tstl == labels)]` creates a **matrix** with:% - `unique(tlab)` → returns all distinct label values in the training set (1 to 10 after our earlier shift).% - First row = class labels (1 to 10)% - Second row = number of training samples per class% - Third row = number of test samples per classlabels = unique(tlab)';[labels; sum(tlab == labels); sum(tstl == labels)]% compute and perform PCA transformation% - `pcaTransform()` applies the learned PCA transformation:% - Subtracts the mean (`mu`) from each sample (centering)% - Projects the result onto the PCA directions (`trmx`)% - This is done for both **training data** (`tvec`) and **test data** (`tstv`).[mu trmx] = prepTransform(tvec, comp_count);tvec = pcaTransform(tvec, mu, trmx);tstv = pcaTransform(tstv, mu, trmx);% To successfully prepare ensemble you have to implement perceptron function% I would use 10 first zeros and 10 fisrt ones % and only 2 first primary components% It'll allow printing of intermediate results in perceptron function% select and visualize samples from digits '0' and '1'% - extracts 10 samples of digit '0' and digit '1' from training data% - uses only the first two PCA components for 2D visualization% - assigns digit '0' samples to `pclass` and digit '1' samples to `nclass`% - plots both classes using red stars (`r*`) and blue squares (`bs`)tenzeros = tvec(tlab == 1, 1:2)(1:10, :);tenones = tvec(tlab == 2, 1:2)(1:10, :);pclass = tenzeros;nclass = tenones;plot(tenzeros(:,1), tenzeros(:,2), "r*", tenones(:,1), tenones(:,2), "bs")%% YOUR CODE GOES HERE - testing of the perceptron function% Now experiment with the margin % It make sense to use "easy" (0 vs. 1) and "difficult" (4 vs. 9) cases.%%% YOUR CODE GOES HERE - experiments with margins in the perceptron function% training of the whole ensemble% - trains a one-vs-one (OVO) ensemble using perceptron classifiers% - applies the trained ensemble on the training set and computes predictionsovo = trainOVOensemble(tvec, tlab, @perceptron);% check your ensemble on train set% - evaluates performance using confusion matrix (`confMx`) and error computation (`compErrors`)clab = unamvoting(tvec, ovo);cfmx = confMx(tlab, clab)compErrors(cfmx)% repeat on test set% - repeats the same evaluation on the test set to assess generalizationclab = unamvoting(tstv, ovo);cfmx = confMx(tstl, clab)compErrors(cfmx)%% YOUR CODE GOES HERE% Train and test the OVR ensemble% check your ensemble on train set% - evaluates performance using confusion matrix (`confMx`) and error computation (`compErrors`)clab = unamvoting(tvec, ovr);cfmx = confMx(tlab, clab)compErrors(cfmx)% repeat on test set% - repeats the same evaluation on the test set to assess generalizationclab = unamvoting(tstv, ovr);cfmx = confMx(tstl, clab)compErrors(cfmx)% expand features% trainExp = expandFeatures(tvec);% testExp = expandFeatures(tstv);% Train and test the OVO ensemble on the expanded features% Train and test the OVR ensemble on the expanded features% Think about improving your classifier further :)